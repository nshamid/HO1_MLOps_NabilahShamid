{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPz6AvOyiEZ5SqodtUNy6LA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nshamid/HO1_MLOps_NabilahShamid/blob/main/HO1_MLOps_NabilahShamid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Source"
      ],
      "metadata": {
        "id": "odmJWCXJpByS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2DordBA8hutL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset diunggah di Github untuk kemudahan akses\n",
        "dataset_url = 'https://github.com/nshamid/HO1_MLOps_NabilahShamid/raw/refs/heads/main/data_scientist_jobstreet_scraped_v2.zip'\n",
        "\n",
        "# Unduh file ZIP\n",
        "response = requests.get(dataset_url)\n",
        "with open('dataset.zip', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(\"ZIP file berhasil diunduh!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp0YPnBChvre",
        "outputId": "f2888ee2-04d7-46b4-ac14-d0e0d8b7d08f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIP file berhasil diunduh!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengecek nama file\n",
        "with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
        "    file_list = zip_ref.namelist()\n",
        "    print(\"Isi file di dalam ZIP:\")\n",
        "    for f in file_list:\n",
        "        print(f)\n",
        "\n",
        "    # Ekstrak semua file\n",
        "    zip_ref.extractall()\n",
        "\n",
        "print(\"ZIP file berhasil diekstrak!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WPtsPnlixa4",
        "outputId": "4b902c78-7ef2-4478-be37-d28ecf8de85c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isi file di dalam ZIP:\n",
            "data_scientist_jobstreet_scraped_v2.csv\n",
            "ZIP file berhasil diekstrak!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'data_scientist_jobstreet_scraped_v2.csv'\n",
        "\n",
        "# Load CSV ke DataFrame\n",
        "df = pd.read_csv(file_name)"
      ],
      "metadata": {
        "id": "JpBY01WOi01f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgWCRcrTjA3I",
        "outputId": "e95b4e15-1448-40af-83de-23556684b77d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0    job_id                              job_title  \\\n",
            "0           0  72761527                          Data Engineer   \n",
            "1           1  72787241         Machine Learning Engineer (AI)   \n",
            "2           2  72866732               Senior Risk/Data Analyst   \n",
            "3           3  72851872  Senior Data Engineer (Hybrid Working)   \n",
            "4           4  72526811        Data Scientist (Hybrid Working)   \n",
            "\n",
            "                             company  \\\n",
            "0          ANHSIN TECHNOLOGY SDN BHD   \n",
            "1            Accordia Global Sdn Bhd   \n",
            "2  Toyota Capital Malaysia Sdn. Bhd.   \n",
            "3                               SEEK   \n",
            "4              SEEK Asia (JobStreet)   \n",
            "\n",
            "                                        descriptions          location  \\\n",
            "0  Design, develop, and maintain scalable and rob...      Kuala Lumpur   \n",
            "1  Design, develop, and deploy machine learning m...  Shah Alam/Subang   \n",
            "2  Analyse data to better understand potential ri...          Petaling   \n",
            "3  Design, development, testing, and operation of...      Kuala Lumpur   \n",
            "4  Research, build, deploy and maintain Recommend...      Kuala Lumpur   \n",
            "\n",
            "                                 category  \\\n",
            "0                    Science & Technology   \n",
            "1                    Science & Technology   \n",
            "2            Banking & Financial Services   \n",
            "3  Information & Communication Technology   \n",
            "4  Information & Communication Technology   \n",
            "\n",
            "                                      subcategory       type  \\\n",
            "0  Mathematics, Statistics & Information Sciences  Full time   \n",
            "1  Mathematics, Statistics & Information Sciences  Full time   \n",
            "2                               Compliance & Risk  Full time   \n",
            "3                          Engineering - Software  Full time   \n",
            "4                          Developers/Programmers  Full time   \n",
            "\n",
            "                          salary  \n",
            "0                            NaN  \n",
            "1  RM 5,000 – RM 7,000 per month  \n",
            "2                            NaN  \n",
            "3                            NaN  \n",
            "4                            NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLgKHDagjO_3",
        "outputId": "043cbcf6-00a7-4495-e9b9-4b051b407b62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 606 entries, 0 to 605\n",
            "Data columns (total 10 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   Unnamed: 0    606 non-null    int64 \n",
            " 1   job_id        606 non-null    int64 \n",
            " 2   job_title     606 non-null    object\n",
            " 3   company       606 non-null    object\n",
            " 4   descriptions  588 non-null    object\n",
            " 5   location      606 non-null    object\n",
            " 6   category      606 non-null    object\n",
            " 7   subcategory   606 non-null    object\n",
            " 8   type          606 non-null    object\n",
            " 9   salary        198 non-null    object\n",
            "dtypes: int64(2), object(8)\n",
            "memory usage: 47.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepocessing"
      ],
      "metadata": {
        "id": "goYNyjGBvqAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas nltk Sastrawi nlp-id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b7OndPss0h4",
        "outputId": "d449a01f-1339-4133-be17-06fa36bc51df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Collecting nlp-id\n",
            "  Downloading nlp_id-0.1.19.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting huggingface-hub==0.31.1 (from nlp-id)\n",
            "  Downloading huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (from nlp-id) (1.6.1)\n",
            "Requirement already satisfied: scipy==1.15.3 in /usr/local/lib/python3.11/dist-packages (from nlp-id) (1.15.3)\n",
            "Collecting wget==3.2 (from nlp-id)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.31.1->nlp-id) (1.1.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1->nlp-id) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.31.1->nlp-id) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.31.1->nlp-id) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.31.1->nlp-id) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.31.1->nlp-id) (2025.7.9)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlp_id-0.1.19.0-py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.3/484.3 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=c236664228d84f75376a2edccbcb3207095ffc335b095d4306ea2cb91032791b\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, Sastrawi, huggingface-hub, nlp-id\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.2\n",
            "    Uninstalling huggingface-hub-0.33.2:\n",
            "      Successfully uninstalled huggingface-hub-0.33.2\n",
            "Successfully installed Sastrawi-1.0.1 huggingface-hub-0.31.1 nlp-id-0.1.19.0 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6V2GFdQs4DZ",
        "outputId": "e4e07bb5-8669-4f72-b6fc-e62aed96c2d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nlp_id.lemmatizer import Lemmatizer\n",
        "\n",
        "# Inisialisasi stemmer dari Sastrawi\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Inisialisasi lemmatizer dari nlp_id\n",
        "lemmatizer = Lemmatizer()\n",
        "\n",
        "print(\"Library berhasil diimpor dan tools preprocessing diinisialisasi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r97Ac1k0s5g7",
        "outputId": "b624ff23-f6d7-49fc-b92c-122176e3532d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library berhasil diimpor dan tools preprocessing diinisialisasi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menerapkan prepoccessing pada kolom\n",
        "1. job_title (Judul Pekerjaan)\n",
        "\n",
        "2. descriptions (Deskripsi Pekerjaan)"
      ],
      "metadata": {
        "id": "0jvgztZuijCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_noise(text):\n",
        "  # Menghapus semua tag HTML\n",
        "  text = re.sub(r'<.*?>', '', text)\n",
        "  # Menghapus URL\n",
        "  text = re.sub(r'https?://\\\\S+|www\\\\.\\\\S+', '', text)\n",
        "  # Menghapus Hashtag\n",
        "  text = re.sub(r'#\\\\w+', '', text)\n",
        "  # Menggunakan re.sub(r'[^\\w\\s]', '', text)\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  # Menghapus Angka\n",
        "  text = re.sub(r'\\\\d+', '', text)\n",
        "  # Menghapus spasi berlebih\n",
        "  text = re.sub(r'\\\\s+', ' ', text).strip()\n",
        "  return text\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  list_stopwords = stopwords.words('indonesian')\n",
        "  tokens = text.split()\n",
        "  tokens_without_stopwords = [word for word in tokens if word not in list_stopwords]\n",
        "  text = ' '.join(tokens_without_stopwords)\n",
        "  return text\n",
        "\n",
        "def cleaning_pipeline(text):\n",
        "  if not isinstance(text, str):\n",
        "      return text\n",
        "\n",
        "  text = text.lower() # 1. Lowercasing\n",
        "  text = clean_noise(text) # 2. Menghapus Noise\n",
        "  text = remove_stopwords(text) # 3. Menghapus Stopwords\n",
        "  text = stemmer.stem(text) # 4. Stemming\n",
        "  return text\n",
        "\n",
        "def normalize_categorical_string(text):\n",
        "  if not isinstance(text, str):\n",
        "      return text\n",
        "  return text.lower().strip()\n",
        "\n",
        "print(\"Fungsi-fungsi preprocessing telah didefinisikan (termasuk perbaikan regex untuk spasi).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzTmIoabs9Vw",
        "outputId": "e60af2ba-8b06-489a-cae3-5235520141d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi-fungsi preprocessing telah didefinisikan (termasuk perbaikan regex untuk spasi).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muat dataset dari file CSV\n",
        "try:\n",
        "    # Menghapus kolom 'Unnamed'\n",
        "    if 'Unnamed: 0' in df.columns:\n",
        "        df = df.drop('Unnamed: 0', axis=1)\n",
        "        print(\"\\nKolom 'Unnamed: 0' berhasil dihapus.\")\n",
        "\n",
        "    print(\"\\nMenerapkan cleaning pipeline (full cleaning) ke kolom teks bebas:\")\n",
        "\n",
        "    print(\"- Kolom 'job_title'...\")\n",
        "    df['cleaned_job_title'] = df['job_title'].apply(cleaning_pipeline)\n",
        "\n",
        "    print(\"- Kolom 'descriptions'...\")\n",
        "    df['cleaned_descriptions'] = df['descriptions'].apply(cleaning_pipeline)\n",
        "\n",
        "    print(\"\\nMenerapkan normalisasi ringan ke kolom string kategori:\")\n",
        "    columns_to_normalize_lightly = ['company', 'location', 'category', 'subcategory', 'type']\n",
        "    for col in columns_to_normalize_lightly:\n",
        "        if col in df.columns:\n",
        "            df[f'normalized_{col}'] = df[col].apply(normalize_categorical_string)\n",
        "            print(f\"- Kolom '{col}' dinormalisasi ke 'normalized_{col}'.\")\n",
        "        else:\n",
        "            print(f\"- Peringatan: Kolom '{col}' tidak ditemukan.\")\n",
        "\n",
        "    print(\"\\nDataFrame head setelah pembersihan dan normalisasi (kolom relevan):\")\n",
        "    # Menampilkan beberapa kolom original dan yang sudah dibersihkan/dinormalisasi\n",
        "    print(df[['job_title', 'cleaned_job_title',\n",
        "              'descriptions', 'cleaned_descriptions',\n",
        "              'company', 'normalized_company',\n",
        "              'location', 'normalized_location',\n",
        "              'category', 'normalized_category',\n",
        "              'subcategory', 'normalized_subcategory',\n",
        "              'type', 'normalized_type']].head())\n",
        "\n",
        "    # Tampilkan kembali info DataFrame untuk melihat kolom baru\n",
        "    print(\"\\nDataFrame info setelah penambahan kolom bersih/normalisasi:\")\n",
        "    print(df.info())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: File 'data_scientist_jobstreet_scraped_v2.csv' tidak ditemukan. Pastikan file sudah diunggah.\")\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Kolom {e} tidak ditemukan di DataFrame. Pastikan nama kolom sudah benar.\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi kesalahan saat memuat atau memproses data: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJP1xozPtA-U",
        "outputId": "e4b5a404-2fba-4d15-ade9-f5ed8eccfd14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kolom 'Unnamed: 0' berhasil dihapus.\n",
            "\n",
            "Menerapkan cleaning pipeline (full cleaning) ke kolom teks bebas:\n",
            "- Kolom 'job_title'...\n",
            "- Kolom 'descriptions'...\n",
            "\n",
            "Menerapkan normalisasi ringan ke kolom string kategori:\n",
            "- Kolom 'company' dinormalisasi ke 'normalized_company'.\n",
            "- Kolom 'location' dinormalisasi ke 'normalized_location'.\n",
            "- Kolom 'category' dinormalisasi ke 'normalized_category'.\n",
            "- Kolom 'subcategory' dinormalisasi ke 'normalized_subcategory'.\n",
            "- Kolom 'type' dinormalisasi ke 'normalized_type'.\n",
            "\n",
            "DataFrame head setelah pembersihan dan normalisasi (kolom relevan):\n",
            "                               job_title                    cleaned_job_title  \\\n",
            "0                          Data Engineer                        data engineer   \n",
            "1         Machine Learning Engineer (AI)         machine learning engineer ai   \n",
            "2               Senior Risk/Data Analyst              senior riskdata analyst   \n",
            "3  Senior Data Engineer (Hybrid Working)  senior data engineer hybrid working   \n",
            "4        Data Scientist (Hybrid Working)        data scientist hybrid working   \n",
            "\n",
            "                                        descriptions  \\\n",
            "0  Design, develop, and maintain scalable and rob...   \n",
            "1  Design, develop, and deploy machine learning m...   \n",
            "2  Analyse data to better understand potential ri...   \n",
            "3  Design, development, testing, and operation of...   \n",
            "4  Research, build, deploy and maintain Recommend...   \n",
            "\n",
            "                                cleaned_descriptions  \\\n",
            "0  design develop and maintain scalable and robus...   \n",
            "1  design develop and deploy machine learning mod...   \n",
            "2  analyse data to better understand potential ri...   \n",
            "3  design development testing and operation of bi...   \n",
            "4  research build deploy and maintain recommendat...   \n",
            "\n",
            "                             company                 normalized_company  \\\n",
            "0          ANHSIN TECHNOLOGY SDN BHD          anhsin technology sdn bhd   \n",
            "1            Accordia Global Sdn Bhd            accordia global sdn bhd   \n",
            "2  Toyota Capital Malaysia Sdn. Bhd.  toyota capital malaysia sdn. bhd.   \n",
            "3                               SEEK                               seek   \n",
            "4              SEEK Asia (JobStreet)              seek asia (jobstreet)   \n",
            "\n",
            "           location normalized_location  \\\n",
            "0      Kuala Lumpur        kuala lumpur   \n",
            "1  Shah Alam/Subang    shah alam/subang   \n",
            "2          Petaling            petaling   \n",
            "3      Kuala Lumpur        kuala lumpur   \n",
            "4      Kuala Lumpur        kuala lumpur   \n",
            "\n",
            "                                 category  \\\n",
            "0                    Science & Technology   \n",
            "1                    Science & Technology   \n",
            "2            Banking & Financial Services   \n",
            "3  Information & Communication Technology   \n",
            "4  Information & Communication Technology   \n",
            "\n",
            "                      normalized_category  \\\n",
            "0                    science & technology   \n",
            "1                    science & technology   \n",
            "2            banking & financial services   \n",
            "3  information & communication technology   \n",
            "4  information & communication technology   \n",
            "\n",
            "                                      subcategory  \\\n",
            "0  Mathematics, Statistics & Information Sciences   \n",
            "1  Mathematics, Statistics & Information Sciences   \n",
            "2                               Compliance & Risk   \n",
            "3                          Engineering - Software   \n",
            "4                          Developers/Programmers   \n",
            "\n",
            "                           normalized_subcategory       type normalized_type  \n",
            "0  mathematics, statistics & information sciences  Full time       full time  \n",
            "1  mathematics, statistics & information sciences  Full time       full time  \n",
            "2                               compliance & risk  Full time       full time  \n",
            "3                          engineering - software  Full time       full time  \n",
            "4                          developers/programmers  Full time       full time  \n",
            "\n",
            "DataFrame info setelah penambahan kolom bersih/normalisasi:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 606 entries, 0 to 605\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   job_id                  606 non-null    int64 \n",
            " 1   job_title               606 non-null    object\n",
            " 2   company                 606 non-null    object\n",
            " 3   descriptions            588 non-null    object\n",
            " 4   location                606 non-null    object\n",
            " 5   category                606 non-null    object\n",
            " 6   subcategory             606 non-null    object\n",
            " 7   type                    606 non-null    object\n",
            " 8   salary                  198 non-null    object\n",
            " 9   cleaned_job_title       606 non-null    object\n",
            " 10  cleaned_descriptions    588 non-null    object\n",
            " 11  normalized_company      606 non-null    object\n",
            " 12  normalized_location     606 non-null    object\n",
            " 13  normalized_category     606 non-null    object\n",
            " 14  normalized_subcategory  606 non-null    object\n",
            " 15  normalized_type         606 non-null    object\n",
            "dtypes: int64(1), object(15)\n",
            "memory usage: 75.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in locals() and not df.empty:\n",
        "    # Simpan ke CSV\n",
        "    csv_filename = 'cleaned_job_data.csv'\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "    print(f\"\\nData bersih berhasil disimpan ke file CSV: '{csv_filename}'\")\n",
        "\n",
        "    # Simpan ke JSON\n",
        "    json_filename = 'cleaned_job_data.json'\n",
        "    df.to_json(json_filename, orient='records', indent=4)\n",
        "    print(f\"Data bersih berhasil disimpan ke file JSON: '{json_filename}'\")\n",
        "else:\n",
        "    print(\"DataFrame kosong atau tidak ditemukan. Pastikan langkah memuat dan memproses data berhasil.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8eRSSsjtE-S",
        "outputId": "60a6ac28-96a3-4860-ae6f-6a9016b6b46d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data bersih berhasil disimpan ke file CSV: 'cleaned_job_data.csv'\n",
            "Data bersih berhasil disimpan ke file JSON: 'cleaned_job_data.json'\n"
          ]
        }
      ]
    }
  ]
}